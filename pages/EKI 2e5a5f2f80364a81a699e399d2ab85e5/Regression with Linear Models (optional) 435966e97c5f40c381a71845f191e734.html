<html><head><meta content="text/html; charset=utf-8" http-equiv="Content-Type"/><title>Regression with Linear Models (optional)</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
-webkit-print-color-adjust: exact;
}
* {
box-sizing: border-box;
-webkit-print-color-adjust: exact;
}html,
body {
margin: 0;
padding: 0;
}
@media only screen {
body {
margin: 2em auto;
max-width: 900px;
color: rgb(55, 53, 47);
}
}body {
line-height: 1.5;
white-space: pre-wrap;
}a,
a.visited {
color: inherit;
text-decoration: underline;
}.pdf-relative-link-path {
font-size: 80%;
color: #444;
}h1,
h2,
h3 {
letter-spacing: -0.01em;
line-height: 1.2;
font-weight: 600;
margin-bottom: 0;
}.page-title {
font-size: 2.5rem;
font-weight: 700;
margin-top: 0;
margin-bottom: 0.75em;
}h1 {
font-size: 1.875rem;
margin-top: 1.875rem;
}h2 {
font-size: 1.5rem;
margin-top: 1.5rem;
}h3 {
font-size: 1.25rem;
margin-top: 1.25rem;
}.source {
border: 1px solid #ddd;
border-radius: 3px;
padding: 1.5em;
word-break: break-all;
}.callout {
border-radius: 3px;
padding: 1rem;
}figure {
margin: 1.25em 0;
page-break-inside: avoid;
}figcaption {
opacity: 0.5;
font-size: 85%;
margin-top: 0.5em;
}mark {
background-color: transparent;
}.indented {
padding-left: 1.5em;
}hr {
background: transparent;
display: block;
width: 100%;
height: 1px;
visibility: visible;
border: none;
border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}img {
max-width: 100%;
}@media only print {
img {
max-height: 100vh;
object-fit: contain;
}
}@page {
margin: 1in;
}.collection-content {
font-size: 0.875rem;
}.column-list {
display: flex;
justify-content: space-between;
}.column {
padding: 0 1em;
}.column:first-child {
padding-left: 0;
}.column:last-child {
padding-right: 0;
}.table_of_contents-item {
display: block;
font-size: 0.875rem;
line-height: 1.3;
padding: 0.125rem;
}.table_of_contents-indent-1 {
margin-left: 1.5rem;
}.table_of_contents-indent-2 {
margin-left: 3rem;
}.table_of_contents-indent-3 {
margin-left: 4.5rem;
}.table_of_contents-link {
text-decoration: none;
opacity: 0.7;
border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}table,
th,
td {
border: 1px solid rgba(55, 53, 47, 0.09);
border-collapse: collapse;
}table {
border-left: none;
border-right: none;
}th,
td {
font-weight: normal;
padding: 0.25em 0.5em;
line-height: 1.5;
min-height: 1.5em;
text-align: left;
}th {
color: rgba(55, 53, 47, 0.6);
}ol,
ul {
margin: 0;
margin-block-start: 0.6em;
margin-block-end: 0.6em;
}li > ol:first-child,
li > ul:first-child {
margin-block-start: 0.6em;
}ul > li {
list-style: disc;
}ul.to-do-list {
padding-inline-start: 0;
}ul.to-do-list > li {
list-style: none;
}.to-do-children-checked {
text-decoration: line-through;
opacity: 0.375;
}ul.toggle > li {
list-style: none;
}ul {
padding-inline-start: 1.7em;
}ul > li {
padding-left: 0.1em;
}ol {
padding-inline-start: 1.6em;
}ol > li {
padding-left: 0.2em;
}.mono ol {
padding-inline-start: 2em;
}.mono ol > li {
text-indent: -0.4em;
}.toggle {
padding-inline-start: 0em;
list-style-type: none;
}/* Indent toggle children */
.toggle > li > details {
padding-left: 1.7em;
}.toggle > li > details > summary {
margin-left: -1.1em;
}.selected-value {
display: inline-block;
padding: 0 0.5em;
background: rgba(206, 205, 202, 0.5);
border-radius: 3px;
margin-right: 0.5em;
margin-top: 0.3em;
margin-bottom: 0.3em;
white-space: nowrap;
}.collection-title {
display: inline-block;
margin-right: 1em;
}.page-description {
margin-bottom: 2em;
}.simple-table {
margin-top: 1em;
font-size: 0.875rem;
empty-cells: show;
}
.simple-table td {
height: 29px;
min-width: 120px;
}.simple-table th {
height: 29px;
min-width: 120px;
}.simple-table-header-color {
background: rgb(247, 246, 243);
color: black;
}
.simple-table-header {
font-weight: 500;
}time {
opacity: 0.5;
}.icon {
display: inline-block;
max-width: 1.2em;
max-height: 1.2em;
text-decoration: none;
vertical-align: text-bottom;
margin-right: 0.5em;
}img.icon {
border-radius: 3px;
}.user-icon {
width: 1.5em;
height: 1.5em;
border-radius: 100%;
margin-right: 0.5rem;
}.user-icon-inner {
font-size: 0.8em;
}.text-icon {
border: 1px solid #000;
text-align: center;
}.page-cover-image {
display: block;
object-fit: cover;
width: 100%;
max-height: 30vh;
}.page-header-icon {
font-size: 3rem;
margin-bottom: 1rem;
}.page-header-icon-with-cover {
margin-top: -0.72em;
margin-left: 0.07em;
}.page-header-icon img {
border-radius: 3px;
}.link-to-page {
margin: 1em 0;
padding: 0;
border: none;
font-weight: 500;
}p > .user {
opacity: 0.5;
}td > .user,
td > time {
white-space: nowrap;
}input[type="checkbox"] {
transform: scale(1.5);
margin-right: 0.6em;
vertical-align: middle;
}p {
margin-top: 0.5em;
margin-bottom: 0.5em;
}.image {
border: none;
margin: 1.5em 0;
padding: 0;
border-radius: 0;
text-align: center;
}.code,
code {
background: rgba(135, 131, 120, 0.15);
border-radius: 3px;
padding: 0.2em 0.4em;
border-radius: 3px;
font-size: 85%;
tab-size: 2;
}code {
color: #eb5757;
}.code {
padding: 1.5em 1em;
}.code-wrap {
white-space: pre-wrap;
word-break: break-all;
}.code > code {
background: none;
padding: 0;
font-size: 100%;
color: inherit;
}blockquote {
font-size: 1.25em;
margin: 1em 0;
padding-left: 1em;
border-left: 3px solid rgb(55, 53, 47);
}.bookmark {
text-decoration: none;
max-height: 8em;
padding: 0;
display: flex;
width: 100%;
align-items: stretch;
}.bookmark-title {
font-size: 0.85em;
overflow: hidden;
text-overflow: ellipsis;
height: 1.75em;
white-space: nowrap;
}.bookmark-text {
display: flex;
flex-direction: column;
}.bookmark-info {
flex: 4 1 180px;
padding: 12px 14px 14px;
display: flex;
flex-direction: column;
justify-content: space-between;
}.bookmark-image {
width: 33%;
flex: 1 1 180px;
display: block;
position: relative;
object-fit: cover;
border-radius: 1px;
}.bookmark-description {
color: rgba(55, 53, 47, 0.6);
font-size: 0.75em;
overflow: hidden;
max-height: 4.5em;
word-break: break-word;
}.bookmark-href {
font-size: 0.75em;
margin-top: 0.25em;
}.sans {
font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji",
"Segoe UI Symbol";
}
.code {
font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace;
}
.serif {
font-family: Lyon-Text, Georgia, ui-serif, serif;
}
.mono {
font-family: iawriter-mono, Nitti, Menlo, Courier, monospace;
}
.pdf .sans {
font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif,
"Segoe UI Emoji", "Segoe UI Symbol", "Twemoji", "Noto Color Emoji", "Noto Sans CJK JP";
}
.pdf:lang(zh-CN) .sans {
font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif,
"Segoe UI Emoji", "Segoe UI Symbol", "Twemoji", "Noto Color Emoji", "Noto Sans CJK SC";
}
.pdf:lang(zh-TW) .sans {
font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif,
"Segoe UI Emoji", "Segoe UI Symbol", "Twemoji", "Noto Color Emoji", "Noto Sans CJK TC";
}
.pdf:lang(ko-KR) .sans {
font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif,
"Segoe UI Emoji", "Segoe UI Symbol", "Twemoji", "Noto Color Emoji", "Noto Sans CJK KR";
}
.pdf .code {
font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, "Twemoji", "Noto Color Emoji",
"Noto Sans Mono CJK JP";
}
.pdf:lang(zh-CN) .code {
font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, "Twemoji", "Noto Color Emoji",
"Noto Sans Mono CJK SC";
}
.pdf:lang(zh-TW) .code {
font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, "Twemoji", "Noto Color Emoji",
"Noto Sans Mono CJK TC";
}
.pdf:lang(ko-KR) .code {
font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, "Twemoji", "Noto Color Emoji",
"Noto Sans Mono CJK KR";
}
.pdf .serif {
font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, "Twemoji", "Noto Color Emoji", "Noto Serif CJK JP";
}
.pdf:lang(zh-CN) .serif {
font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, "Twemoji", "Noto Color Emoji", "Noto Serif CJK SC";
}
.pdf:lang(zh-TW) .serif {
font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, "Twemoji", "Noto Color Emoji", "Noto Serif CJK TC";
}
.pdf:lang(ko-KR) .serif {
font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, "Twemoji", "Noto Color Emoji", "Noto Serif CJK KR";
}
.pdf .mono {
font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, "Twemoji", "Noto Color Emoji", "Noto Sans Mono CJK JP";
}
.pdf:lang(zh-CN) .mono {
font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, "Twemoji", "Noto Color Emoji", "Noto Sans Mono CJK SC";
}
.pdf:lang(zh-TW) .mono {
font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, "Twemoji", "Noto Color Emoji", "Noto Sans Mono CJK TC";
}
.pdf:lang(ko-KR) .mono {
font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, "Twemoji", "Noto Color Emoji", "Noto Sans Mono CJK KR";
}
.highlight-default {
color: rgba(55, 53, 47, 1);
}
.highlight-gray {
color: rgba(120, 119, 116, 1);
fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
color: rgba(159, 107, 83, 1);
fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
color: rgba(217, 115, 13, 1);
fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
color: rgba(203, 145, 47, 1);
fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
color: rgba(68, 131, 97, 1);
fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
color: rgba(51, 126, 169, 1);
fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
color: rgba(144, 101, 176, 1);
fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
color: rgba(193, 76, 138, 1);
fill: rgba(193, 76, 138, 1);
}
.highlight-red {
color: rgba(212, 76, 71, 1);
fill: rgba(212, 76, 71, 1);
}
.highlight-gray_background {
background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
background: rgba(251, 243, 219, 1);
}
.highlight-teal_background {
background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
background: rgba(253, 235, 236, 1);
}
.block-color-default {
color: inherit;
fill: inherit;
}
.block-color-gray {
color: rgba(120, 119, 116, 1);
fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
color: rgba(159, 107, 83, 1);
fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
color: rgba(217, 115, 13, 1);
fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
color: rgba(203, 145, 47, 1);
fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
color: rgba(68, 131, 97, 1);
fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
color: rgba(51, 126, 169, 1);
fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
color: rgba(144, 101, 176, 1);
fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
color: rgba(193, 76, 138, 1);
fill: rgba(193, 76, 138, 1);
}
.block-color-red {
color: rgba(212, 76, 71, 1);
fill: rgba(212, 76, 71, 1);
}
.block-color-gray_background {
background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
background: rgba(251, 243, 219, 1);
}
.block-color-teal_background {
background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
background: rgba(253, 235, 236, 1);
}
.select-value-color-interactiveBlue {
background-color: rgba(35, 131, 226, 0.07);
}
.select-value-color-pink {
background-color: rgba(245, 224, 233, 1);
}
.select-value-color-purple {
background-color: rgba(232, 222, 238, 1);
}
.select-value-color-green {
background-color: rgba(219, 237, 219, 1);
}
.select-value-color-gray {
background-color: rgba(227, 226, 224, 1);
}
.select-value-color-translucentGray {
background-color: rgba(255, 255, 255, 0.0375);
}
.select-value-color-orange {
background-color: rgba(250, 222, 201, 1);
}
.select-value-color-brown {
background-color: rgba(238, 224, 218, 1);
}
.select-value-color-red {
background-color: rgba(255, 226, 221, 1);
}
.select-value-color-yellow {
background-color: rgba(253, 236, 200, 1);
}
.select-value-color-blue {
background-color: rgba(211, 229, 239, 1);
}
.select-value-color-pageGlass {
background-color: undefined;
}
.select-value-color-washGlass {
background-color: undefined;
}.checkbox {
display: inline-flex;
vertical-align: text-bottom;
width: 16;
height: 16;
background-size: 16px;
margin-left: 2px;
margin-right: 5px;
}.checkbox-on {
background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}.checkbox-off {
background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}/* -------- injections from notionBackup -------- */body {
white-space: normal !important;
}p {
min-height: 1em !important;
}.code,
code {
font-size: 100% !important;
}blockquote {
font-size: 100% !important;
}.callout {
white-space: normal !important;
}
.callout div:has(span.icon) {
font-size: 100% !important;
}.source:not(.bookmark) {
font-size: 100% !important;
}p {
min-height: 1em !important;
}
</style></head><body><article class="page sans"><header><h1 class="page-title">Regression with Linear Models (optional)</h1><p class="page-description"></p></header><div class="page-body"><h1>Linear Regression</h1><p>
Hypothesis space
<style>
@import url("https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css");
</style><span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select: all; -webkit-user-select: all; -moz-user-select: all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">H</mi></mrow><annotation encoding="application/x-tex">\mathcal{H}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height: 0.68333em; vertical-align: 0em"></span><span class="mord mathcal" style="margin-right: 0.00965em">H</span></span></span></span></span><span>﻿</span></span>
:
<mark class="highlight-teal">linear functions</mark>
for continuous valued inputs.
</p><h1>Univariate linear regression</h1><p><mark class="highlight-teal">Goal: Fitting a straight line so that we minimize the error (empirical loss)</mark></p><p>
The weights
<style>
@import url("https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css");
</style><span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select: all; -webkit-user-select: all; -moz-user-select: all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>w</mi></mrow><annotation encoding="application/x-tex">w</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em"></span><span class="mord mathnormal" style="margin-right: 0.02691em">w</span></span></span></span></span><span>﻿</span></span>
are the coefficients to be learned - defined as a vector
<style>
@import url("https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css");
</style><span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select: all; -webkit-user-select: all; -moz-user-select: all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mover accent="true"><mi>w</mi><mo>⃗</mo></mover><mo>=</mo><mo stretchy="false">(</mo><msub><mi>w</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>w</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\vec w = (w_0,w_1)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height: 0.714em; vertical-align: 0em"></span><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.714em"><span style="top: -3em"><span class="pstrut" style="height: 3em"></span><span class="mord mathnormal" style="margin-right: 0.02691em">w</span></span><span style="top: -3em"><span class="pstrut" style="height: 3em"></span><span class="accent-body" style="left: -0.15216em"><span class="overlay" style="height: 0.714em; width: 0.471em"><svg height="0.714em" preserveaspectratio="xMinYMin" style="width: 0.471em" viewbox="0 0 471 714" width="0.471em"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2777777777777778em"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.30110799999999993em"><span style="top: -2.5500000000000003em; margin-left: -0.02691em; margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.30110799999999993em"><span style="top: -2.5500000000000003em; margin-left: -0.02691em; margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span><span>﻿</span></span>
.
</p><figure class="equation">hw⃗(x)=w1x+w0h_{\vec w}(x) = w_1x + w_0hw​(x)=w1​x+w0​</figure><p></p><h2>When the derivative has a closed form</h2><p class="block-color-teal">
1.
<mark class="highlight-teal">Calculating the squared loss</mark><mark class="highlight-teal"><style>
@import url("https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css");
</style><span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select: all; -webkit-user-select: all; -moz-user-select: all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.30110799999999993em"><span style="top: -2.5500000000000003em; margin-left: 0em; margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span></mark></p><p>
To calculate the empirical loss we use the squared loss
<style>
@import url("https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css");
</style><span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select: all; -webkit-user-select: all; -moz-user-select: all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.30110799999999993em"><span style="top: -2.5500000000000003em; margin-left: 0em; margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span><mark class="highlight-teal"></mark>
summed over all training examples.
</p><p class="block-color-gray"><mark class="highlight-gray">Gauss proved that with normally distributed noise, this is the best method.</mark></p><figure class="equation">Loss(hw⃗)=∑j=1NL2(yj,hw⃗(xj))=∑j=1N(yj−hw⃗(xj))2=∑j=1N(yj−(w1x+w0))2Loss(h_{\vec w}) = \\ \sum_{j=1}^N \textcolor{pink}{L_2(}y_j,h_{\vec w}(x_j)\textcolor{pink}) = \sum_{j=1}^N                                                \textcolor{pink}(y_j \textcolor{pink}- h_{\vec w}(x_j)\textcolor{pink}{)^2} = \\ \sum_{j=1}^N (y_j - (w_1x +                                                w_0))^2Loss(hw​)=j=1∑N​L2​(yj​,hw​(xj​))=j=1∑N​(yj​−hw​(xj​))2=j=1∑N​(yj​−(w1​x+w0​))2</figure><p><mark class="highlight-teal">2. calculating partial derivatives of the loss to find the minumum</mark></p><p>
We want to find the minimal loss and can do so by calculating the partial derivatives and finding the weights for which the output (of our
loss function) = 0
</p><figure class="equation">∂∂w0Loss(hw⃗)=∂∂w0∑j=1N(yj−(w1x+w0))2=0∂∂w1Loss(hw⃗)=∂∂w1∑j=1N(yj−(w1x+w0))2=0\frac{\partial}{\partial \textcolor{pink}{w_0} } \text{Loss}(h_{\vec w}) = \frac{\partial}{\partial                                                \textcolor{pink}{w_0} } \sum_{j=1}^N (y_j - (w_1x + \textcolor{pink}{w_0}))^2 = 0 \\ \frac{\partial}{\partial                                                \textcolor{pink}{w_1} } \text{Loss}(h_{\vec w}) = \frac{\partial}{\partial \textcolor{pink}{w_1} } \sum_{j=1}^N                                                (y_j - (\textcolor{pink}{w_1}x + w_0))^2 = 0∂w0​∂​Loss(hw​)=∂w0​∂​j=1∑N​(yj​−(w1​x+w0​))2=0∂w1​∂​Loss(hw​)=∂w1​∂​j=1∑N​(yj​−(w1​x+w0​))2=0</figure><p>Which results in:</p><figure class="equation">w1=N(∑xjyj)−(∑xj)(∑yj)N(∑xj2)−(∑xj)2\textcolor{pink}{w_{1}}=\frac{N\left(\sum x_{j} y_{j}\right)-\left(\sum x_{j}\right)\left(\sum                                                y_{j}\right)}{N\left(\sum x_{j}^{2}\right)-\left(\sum x_{j}\right)^{2}}w1​=N(∑xj2​)−(∑xj​)2N(∑xj​yj​)−(∑xj​)(∑yj​)​</figure><figure class="equation">w0=∑yj−w1(∑xj)N\textcolor{pink}{w_{0}}= \frac{\sum y_{j}-w_{1}\left(\sum x_{j}\right)}{N}w0​=N∑yj​−w1​(∑xj​)​</figure><p class="block-color-gray"><mark class="highlight-teal">Example</mark></p><p class="block-color-gray">
Each of the
<style>
@import url("https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css");
</style><span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select: all; -webkit-user-select: all; -moz-user-select: all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em"></span><span class="mord mathnormal">n</span></span></span></span></span><span>﻿</span></span>
points: size in square feet vs price of house.
</p><p class="block-color-gray">
weight space
<em>=</em>
space defined by all possible settings of the weights.
</p><figure class="image"><a href="Regression%20with%20Linear%20Models%20(optional)%20435966e97c5f40c381a71845f191e734/Untitled.png"><img src="Regression%20with%20Linear%20Models%20(optional)%20435966e97c5f40c381a71845f191e734/Untitled.png" style="width: 384px"/></a></figure><p class="block-color-gray">
For univariate linear regression, the weight space is two-dimensional, so we can graph the loss as a function in a 3D plot.
</p><p class="block-color-gray">
loss function is convex → true for every linear regression problem with an squared loss function that means there are no local minima.
</p><p></p><h2>When the derivative does not have a closed form</h2><p>Often when we want to fit linear data we just use these equations and that's the end of the story.</p><p>But other times the derivatives to get to this equation do not have a closed form.</p><div class="indented"><p class="block-color-gray">For example, an infinite sum would generally not be considered closed-form.</p></div><p></p><p>
Then we cant solve this problem with calculus → general optimization search problem in a continuous weight space. → Local search with hill
climbing algorithm.
</p><p></p><h3><mark class="highlight-teal">Hill climbing algorithm</mark></h3><figure class="block-color-gray_background callout" style="white-space: pre-wrap; display: flex"><div style="font-size: 1.5em"><span class="icon">💡</span></div><div style="width: 100%">We need the derivative of the loss to subtract it from the current weight value.</div></figure><p>Convergence to solution is guaranteed but it is very slow.</p><figure class="image"><a href="Regression%20with%20Linear%20Models%20(optional)%20435966e97c5f40c381a71845f191e734/Untitled%201.png"><img src="Regression%20with%20Linear%20Models%20(optional)%20435966e97c5f40c381a71845f191e734/Untitled%201.png" style="width: 288px"/></a></figure><p>
Update each weight with (Where
<style>
@import url("https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css");
</style><span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select: all; -webkit-user-select: all; -moz-user-select: all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em"></span><span class="mord mathnormal" style="margin-right: 0.0037em">α</span></span></span></span></span><span>﻿</span></span>
= step size / learning rate):
</p><p><mark class="highlight-gray">We must individually update</mark><mark class="highlight-gray"><style>
@import url("https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css");
</style><span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select: all; -webkit-user-select: all; -moz-user-select: all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>=</mo><mo stretchy="false">{</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">i = \{0,1\}</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height: 0.65952em; vertical-align: 0em"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right: 0.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2777777777777778em"></span></span><span class="base"><span class="strut" style="height: 1em; vertical-align: -0.25em"></span><span class="mopen">{</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.16666666666666666em"></span><span class="mord">1</span><span class="mclose">}</span></span></span></span></span><span>﻿</span></span></mark><mark class="highlight-gray">.</mark></p><figure class="equation">wi←wi−α⋅∂∂wiLoss⁡(w)w_{i} \leftarrow w_{i}-\alpha \cdot \frac{\partial}{\partial w_{i}} \operatorname{Loss}(\mathbf{w})wi​←wi​−α⋅∂wi​∂​Loss(w)</figure><p></p><p><mark class="highlight-teal">One training example</mark></p><p>Calculating the derivative:</p><p><mark class="highlight-gray">Because</mark><mark class="highlight-gray"><style>
@import url("https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css");
</style><span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select: all; -webkit-user-select: all; -moz-user-select: all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi mathvariant="normal">∂</mi><mrow><mi mathvariant="normal">∂</mi><mi>x</mi></mrow></mfrac><msup><mi>x</mi><mn>2</mn></msup><mo>=</mo><mn>2</mn><mi>x</mi></mrow><annotation encoding="application/x-tex">\frac{\partial}{\partial x} x^2 = 2x</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height: 1.2251079999999999em; vertical-align: -0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8801079999999999em"><span style="top: -2.6550000000000002em"><span class="pstrut" style="height: 3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right: 0.05556em">∂</span><span class="mord mathnormal mtight">x</span></span></span></span><span style="top: -3.23em"><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span style="top: -3.394em"><span class="pstrut" style="height: 3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right: 0.05556em">∂</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.8141079999999999em"><span style="top: -3.063em; margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2777777777777778em"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em"></span><span class="mord">2</span><span class="mord mathnormal">x</span></span></span></span></span><span>﻿</span></span></mark><mark class="highlight-gray">and</mark><mark class="highlight-gray"><style>
@import url("https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css");
</style><span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select: all; -webkit-user-select: all; -moz-user-select: all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi mathvariant="normal">∂</mi><mrow><mi mathvariant="normal">∂</mi><mi>x</mi></mrow></mfrac><mi>x</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\frac{\partial}{\partial x} x = 1</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height: 1.2251079999999999em; vertical-align: -0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.8801079999999999em"><span style="top: -2.6550000000000002em"><span class="pstrut" style="height: 3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right: 0.05556em">∂</span><span class="mord mathnormal mtight">x</span></span></span></span><span style="top: -3.23em"><span class="pstrut" style="height: 3em"></span><span class="frac-line" style="border-bottom-width: 0.04em"></span></span><span style="top: -3.394em"><span class="pstrut" style="height: 3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right: 0.05556em">∂</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right: 0.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2777777777777778em"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em"></span><span class="mord">1</span></span></span></span></span><span>﻿</span></span></mark></p><figure class="equation">∂∂wiLoss⁡(w)=∂∂wi(y−hw(x))2=2(y−hw(x))⋅∂∂wi(y−hw(x))=2(y−hw(x))⋅∂∂wi(y−(w1x+w0))\begin{aligned}\frac{\partial}{\partial \textcolor{pink}{w_{i}}} \operatorname{Loss}(\mathbf{w})                                                &amp;=\frac{\partial}{\partial \textcolor{pink}{w_{i}}}\left(y-h_{\mathbf{w}}(x)\right)^{2}                                                \\&amp;=2\left(y-h_{\mathbf{w}}(x)\right) \cdot\frac{\partial}{\partial                                                \textcolor{pink}{w_{i}}}\left(y-h_{\mathbf{w}}(x)\right) \\&amp;=2\left(y-h_{\mathbf{w}}(x)\right)                                                \cdot\frac{\partial}{\partial \textcolor{pink}{w_{i}}}\left(y-\left(w_{1} x+w_{0}\right)\right)\end{aligned}∂wi​∂​Loss(w)​=∂wi​∂​(y−hw​(x))2=2(y−hw​(x))⋅∂wi​∂​(y−hw​(x))=2(y−hw​(x))⋅∂wi​∂​(y−(w1​x+w0​))​</figure><p>Now for the individual weights:</p><figure class="equation">∂∂w0Loss⁡(w)=−2(y−hw(x))\frac{\partial}{\partial \textcolor{pink}{w_0}}                                                \operatorname{Loss}(\mathbf{w})=-2\left(y-h_{\mathbf{w}}(x)\right)∂w0​∂​Loss(w)=−2(y−hw​(x))</figure><figure class="equation">∂∂w1Loss⁡(w)=−2(y−hw(x))⋅x\\\frac{\partial}{\partial \textcolor{pink}{w_1}}                                                \operatorname{Loss}(\mathbf{w})=-2\left(y-h_{\mathbf{w}}(x)\right) \cdot x∂w1​∂​Loss(w)=−2(y−hw​(x))⋅x</figure><p>Therefore the weights must be updated in each step of the algorithm with</p><figure class="equation">w0←w0+α(y−hw(x))\textcolor{pink}{w_{0}} \leftarrow \textcolor{pink}{w_{0}}+\alpha\left(y-h_{\mathbf{w}}(x)\right)w0​←w0​+α(y−hw​(x))</figure><figure class="equation">w1←w1+α(y−hw(x))⋅x\textcolor{pink}{w_{1}} \leftarrow \textcolor{pink}{w_{1}}+\alpha\left(y-h_{\mathbf{w}}(x)\right) \cdot xw1​←w1​+α(y−hw​(x))⋅x</figure><p></p><p><mark class="highlight-teal">Multiple training examples</mark></p><p>We want to iteratively lower the loss in regards to all examples. There are two variations of training with multiple examples:</p><ol class="numbered-list" start="1" type="1"><li><mark class="highlight-teal">batch gradient descent</mark><p>The derivative of a sum = the sum of the derivatives of all the components (previously in the sum).</p><p>
Gradient decent will reach the unique minimum of the loss function by updating each weight individually with the sum of all training
examples
<style>
@import url("https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css");
</style><span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select: all; -webkit-user-select: all; -moz-user-select: all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x_j, y_j)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height: 1.036108em; vertical-align: -0.286108em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em"><span style="top: -2.5500000000000003em; margin-left: 0em; margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em"><span style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span><span>﻿</span></span>
.
</p><figure class="equation">w0←w0+α∑j(yj−hw(xj))w_{0} \leftarrow w_{0}+\alpha                                                        \textcolor{pink}{\sum_{j}}\left(y_{\textcolor{pink}j}-h_{\mathbf{w}}(x_{\textcolor{pink}j})\right) \\w0​←w0​+αj∑​(yj​−hw​(xj​))</figure><figure class="equation">w1←w1+α∑j(yj−hw(xj))⋅xjw_{1} \leftarrow w_{1}+\alpha                                                        \textcolor{pink}{\sum_{j}}\left(y_{\textcolor{pink}j}-h_{\mathbf{w}}(x_{\textcolor{pink}j})\right) \cdot                                                        x_{\textcolor{pink}j}w1​←w1​+αj∑​(yj​−hw​(xj​))⋅xj​</figure></li></ol><ol class="numbered-list" start="2" type="1"><li><mark class="highlight-teal">stochastic gradient descent</mark><p>We only consider a single randomly chosen example at a time with the equation for single training examples.</p><p>
More efficient, can be done online with data constantly coming in - however, it does not guarantee convergence. It can oscillate
around the minimum without settling down.
</p></li></ol><p></p><h1>Multivariate linear regression</h1><p>
The input
<style>
@import url("https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css");
</style><span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select: all; -webkit-user-select: all; -moz-user-select: all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mover accent="true"><mi>x</mi><mo>⃗</mo></mover><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\vec x_j</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height: 1.000108em; vertical-align: -0.286108em"></span><span class="mord"><span class="mord accent"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height: 0.714em"><span style="top: -3em"><span class="pstrut" style="height: 3em"></span><span class="mord mathnormal">x</span></span><span style="top: -3em"><span class="pstrut" style="height: 3em"></span><span class="accent-body" style="left: -0.20772em"><span class="overlay" style="height: 0.714em; width: 0.471em"><svg height="0.714em" preserveaspectratio="xMinYMin" style="width: 0.471em" viewbox="0 0 471 714" width="0.471em"><path d="M377 20c0-5.333 1.833-10 5.5-14S391 0 397 0c4.667 0 8.667 1.667 12 5
3.333 2.667 6.667 9 10 19 6.667 24.667 20.333 43.667 41 57 7.333 4.667 11
10.667 11 18 0 6-1 10-3 12s-6.667 5-14 9c-28.667 14.667-53.667 35.667-75 63
-1.333 1.333-3.167 3.5-5.5 6.5s-4 4.833-5 5.5c-1 .667-2.5 1.333-4.5 2s-4.333 1
-7 1c-4.667 0-9.167-1.833-13.5-5.5S337 184 337 178c0-12.667 15.667-32.333 47-59
H213l-171-1c-8.667-6-13-12.333-13-19 0-4.667 4.333-11.333 13-20h359
c-16-25.333-24-45-24-59z"></path></svg></span></span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em"><span style="top: -2.5500000000000003em; margin-left: 0em; margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>
from our example
<style>
@import url("https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css");
</style><span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select: all; -webkit-user-select: all; -moz-user-select: all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height: 0.85396em; vertical-align: -0.19444em"></span><span class="mord mathnormal" style="margin-right: 0.05724em">j</span></span></span></span></span><span>﻿</span></span>
is an
<style>
@import url("https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css");
</style><span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select: all; -webkit-user-select: all; -moz-user-select: all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height: 0.43056em; vertical-align: 0em"></span><span class="mord mathnormal">n</span></span></span></span></span><span>﻿</span></span>
-element vector.
</p><p>
Hypothesis space not limited to
<style>
@import url("https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css");
</style><span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select: all; -webkit-user-select: all; -moz-user-select: all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em"></span><span class="mord">2</span></span></span></span></span><span>﻿</span></span>
dimensions / weights:
</p><figure class="equation">hsw(xj)=w0+w1xj,1+⋯+wnxj,n=w0+∑iwixj,ih_{s w}(\mathbf{x}_{j})=w_{0}+w_{1} x_{j, 1}+\cdots+w_{n} x_{j, n}=w_{0}+\sum_{i} w_{i} x_{j, i}hsw​(xj​)=w0​+w1​xj,1​+⋯+wn​xj,n​=w0​+i∑​wi​xj,i​</figure><p>
In this formula the term
<style>
@import url("https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css");
</style><span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select: all; -webkit-user-select: all; -moz-user-select: all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">w_0</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height: 0.58056em; vertical-align: -0.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.30110799999999993em"><span style="top: -2.5500000000000003em; margin-left: -0.02691em; margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>
(intercept) stands out - we define a dummy input attribute
<style>
@import url("https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css");
</style><span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select: all; -webkit-user-select: all; -moz-user-select: all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mrow><mi>j</mi><mo separator="true">,</mo><mn>0</mn></mrow></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">x_{j,0} = 1</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height: 0.716668em; vertical-align: -0.286108em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em"><span style="top: -2.5500000000000003em; margin-left: 0em; margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right: 0.05724em">j</span><span class="mpunct mtight">,</span><span class="mord mtight">0</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right: 0.2777777777777778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right: 0.2777777777777778em"></span></span><span class="base"><span class="strut" style="height: 0.64444em; vertical-align: 0em"></span><span class="mord">1</span></span></span></span></span><span>﻿</span></span>
to make calculations easier.
</p><p>
Then
<style>
@import url("https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css");
</style><span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select: all; -webkit-user-select: all; -moz-user-select: all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height: 0.69444em; vertical-align: 0em"></span><span class="mord mathnormal">h</span></span></span></span></span><span>﻿</span></span>
is simply the dot product of the weights and the input vector
<mark class="highlight-gray">(or the matrix product of the transpose of the weights and the input vector):</mark></p><figure class="equation">hsw(xj)=w⋅xj=w⊤xj=∑iwixj,ih_{s w}\left(\mathbf{x}_{j}\right)=\mathbf{w} \cdot \mathbf{x}_{j}=\mathbf{w}^{\top} \mathbf{x}_{j}=\sum_{i}                                                w_{i} x_{j, i}hsw​(xj​)=w⋅xj​=w⊤xj​=i∑​wi​xj,i​</figure><p>
We now want the minimized squared-error loss
<style>
@import url("https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css");
</style><span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select: all; -webkit-user-select: all; -moz-user-select: all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.30110799999999993em"><span style="top: -2.5500000000000003em; margin-left: 0em; margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em"><span></span></span></span></span></span></span></span></span></span></span><span>﻿</span></span>
over the examples.
</p><p>
Gradient decent will reach the unique minimum of the loss function by updating each weight individually with the sum of all training
examples
<style>
@import url("https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.2/katex.min.css");
</style><span class="notion-text-equation-token" contenteditable="false" data-token-index="0" style="user-select: all; -webkit-user-select: all; -moz-user-select: all"><span></span><span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>x</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(x_j, y_j)</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="base"><span class="strut" style="height: 1.036108em; vertical-align: -0.286108em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em"><span style="top: -2.5500000000000003em; margin-left: 0em; margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right: 0.16666666666666666em"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em"><span style="top: -2.5500000000000003em; margin-left: -0.03588em; margin-right: 0.05em"><span class="pstrut" style="height: 2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right: 0.05724em">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.286108em"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span><span>﻿</span></span>
. ( = batch gradient descent)
</p><figure class="equation">wi←wi+α∑j(yj−hw(xj))⋅xj,iw_{i} \leftarrow w_{i}+\alpha \sum_{j} \left(y_{j}-h_{\mathbf{w}}(\mathbf{x}_{j})\right) \cdot {x}_{j,i}wi​←wi​+αj∑​(yj​−hw​(xj​))⋅xj,i​</figure></div></article></body></html>